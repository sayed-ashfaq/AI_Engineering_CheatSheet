{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Deep Learning Fundamentals Revision",
   "id": "3cb379b273663733"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Topics covering\n",
    "* [X] ~~Neural network Fundamentals - Linearity/Non linearity~~\n",
    "* [x] ~~Activation Functions~~\n",
    "* [ ] ~~Loss Functions - Cross Entropy, MSE vs MAE, Perplexity~~\n",
    "* [ ] Optimizers\n",
    "* [ ] Learning Rate Strategies\n",
    "* [ ] Regularization\n",
    "* [ ] Normalization\n",
    "* [ ] Transformers arch and Attention\n",
    "* [ ] Evaluation\n",
    "* [ ] Stochastic GD, Mini batch, Full batch\n",
    "\n",
    "Every topic you review must answer 3 questions:\n",
    "\n",
    "* What problem does this solve?\n",
    "* When does it fail?\n",
    "* What knob do I turn?\n",
    "\n",
    "If you canâ€™t answer those â†’ you donâ€™t â€œknowâ€ it yet."
   ],
   "id": "abf29e40b839eb57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### How to Study like an Engineer not a student",
   "id": "ec0395038809e482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Good â€” this is the *right* question.\n",
    "Hereâ€™s the **concrete, no-nonsense answer** to *â€œwhat am I supposed to do?â€* given that expectation.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸŽ¯ What You Are ACTUALLY Supposed to Do (One-Day Mode)\n",
    "\n",
    "Your job is **not** to study more theory.\n",
    "Your job is to practice **thinking like the engineer who owns the model**.\n",
    "\n",
    "Below is a **step-by-step action plan** you can literally follow today.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1ï¸âƒ£ Switch Your Study Mode (Non-Negotiable)\n",
    "\n",
    "Stop asking:\n",
    "\n",
    "> â€œDo I remember this?â€\n",
    "\n",
    "Start asking:\n",
    "\n",
    "> â€œIf this breaks in production, what would I change first?â€\n",
    "\n",
    "Every topic you review must answer **3 questions**:\n",
    "\n",
    "* What problem does this solve?\n",
    "* When does it fail?\n",
    "* What knob do I turn?\n",
    "\n",
    "If you canâ€™t answer those â†’ you donâ€™t â€œknowâ€ it yet.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2ï¸âƒ£ Do This Loop for Every Topic (THE Core Skill)\n",
    "\n",
    "###### The **Engineer Loop** (repeat 8â€“10 times today)\n",
    "\n",
    "For **each** concept (e.g. AdamW, LoRA, attention):\n",
    "\n",
    "1. **Explain it out loud in plain English** (no math)\n",
    "2. **Name 1 reason it fails**\n",
    "3. **Name 1 trade-off**\n",
    "\n",
    "Example (AdamW):\n",
    "\n",
    "* What it is: Adaptive optimizer with decoupled weight decay\n",
    "* Fails when: LR too high â†’ unstable fine-tuning\n",
    "* Trade-off: Faster convergence vs less predictable generalization\n",
    "\n",
    "If you can do this â†’ interview-ready.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3ï¸âƒ£ Mandatory â€œDebug Thinkingâ€ Practice\n",
    "\n",
    "Interviewers LOVE this.\n",
    "\n",
    "Pick **one LLM fine-tuning scenario** and rehearse it:\n",
    "\n",
    "###### Scenario:\n",
    "\n",
    "> â€œYour fine-tuned LLM outputs repetitive, low-quality answers.â€\n",
    "\n",
    "Your mental checklist must be automatic:\n",
    "\n",
    "* Data quality (format, duplicates, instruction clarity)\n",
    "* Learning rate too high\n",
    "* Overfitting (too many epochs)\n",
    "* Decoding issue (temperature, top-p)\n",
    "* Tokenization mismatch\n",
    "\n",
    "Say this **in order**.\n",
    "This signals *ownership*.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4ï¸âƒ£ Force Yourself to Talk (Critical)\n",
    "\n",
    "Silent studying will **fail you**.\n",
    "\n",
    "###### Do this:\n",
    "\n",
    "* Open a doc or voice note\n",
    "* Explain these **out loud**:\n",
    "\n",
    "  * Attention\n",
    "  * LoRA\n",
    "  * Why fine-tuning fails\n",
    "  * AdamW vs SGD\n",
    "\n",
    "If you hesitate â†’ thatâ€™s your weak spot. Fix only those.\n",
    "\n",
    "---\n",
    "\n",
    "##### 5ï¸âƒ£ Learn to Say â€œIt Dependsâ€ Correctly\n",
    "\n",
    "This is a senior-level signal.\n",
    "\n",
    "Bad answer:\n",
    "\n",
    "> â€œAdam is better.â€\n",
    "\n",
    "Good answer:\n",
    "\n",
    "> â€œIt depends on model size, batch size, and stability needs.â€\n",
    "\n",
    "Then name **one concrete factor**.\n",
    "\n",
    "Interviewers want **judgment**, not certainty.\n",
    "\n",
    "---\n",
    "\n",
    "##### 6ï¸âƒ£ What NOT to Do (Very Important)\n",
    "\n",
    "âŒ Donâ€™t re-derive backprop\n",
    "âŒ Donâ€™t memorize equations\n",
    "âŒ Donâ€™t chase exotic architectures\n",
    "âŒ Donâ€™t over-optimize metrics talk\n",
    "\n",
    "None of this gets you hired.\n",
    "\n",
    "---\n",
    "\n",
    "##### 7ï¸âƒ£ Final 60-Minute Drill (Before Interview)\n",
    "\n",
    "Do this exact order:\n",
    "\n",
    "1. Explain **attention** in 2 minutes\n",
    "2. Explain **LoRA** in 1 minute\n",
    "3. Explain **why fine-tuning fails** in 2 minutes\n",
    "4. Explain **trade-offs of decoding strategies**\n",
    "5. Answer:\n",
    "\n",
    "   > â€œHow would you improve performance without changing the model?â€\n",
    "\n",
    "If you can do this calmly â†’ you are *absolutely* hireable.\n",
    "\n",
    "---\n",
    "\n",
    "##### The Truth (Coach Mode)\n",
    "\n",
    "Companies hire people who:\n",
    "\n",
    "* Donâ€™t panic when models misbehave\n",
    "* Know which knob to turn first\n",
    "* Can explain decisions clearly\n",
    "\n",
    "Youâ€™re not trying to be brilliant.\n",
    "Youâ€™re trying to be **reliable under pressure**.\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "* Simulate a **real interview** (Iâ€™ll push you)\n",
    "* Turn this into a **1-page interview cheat sheet**\n",
    "* Drill you with **failure-mode questions only**\n",
    "\n",
    "Tell me which one.\n"
   ],
   "id": "68bf47dd427d53e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NN Basics",
   "id": "c5ae836aef555278"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* `Layer`: Layer is a group of neurons that process the input at the same stage\n",
    "* `Weights`: Learned parameters that determine how important each input is.\n",
    "* `bias`: It is constant that is added to weighted sum\n",
    "* `Activation Function`: **Allows the neural networks to understand non linearity** in the data allowing to learn and represent complex data patterns. If no activation function it would collapse into **single linear model**."
   ],
   "id": "1b4e3e62e3ef9812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Activation Functions\n",
    "Activation Functions are mathematical functions applied to neuron's output in a neural network. They decide how much of signal passes forward.\n",
    "\n",
    "> Apart from introducing non-linearity it also controls the output of neurons in neural network"
   ],
   "id": "c024528e36be791c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Common Activation Functions are\n",
    "1. **Sigmoid**\n",
    "- $ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "- Output range - (0 , 1)\n",
    "- Binary Classification output layers.\n",
    "- Problems are Vanishing gradients, Outputs are not zero centered\n",
    "\n",
    "2. **Tanh**\n",
    "- Output range: (-1, 1)\n",
    "- Zero Centered better than sigmoid. Strong gradients\n",
    "- Problem: vanishing gradient\n",
    "\n",
    "3. **Softmax**\n",
    "- Converts a vector of scores into probabilities that sums upto 1.\n",
    "- Used for multiclass classification output layers.\n",
    "\n",
    "4. **ReLU**\n",
    "- $ f(x) = max(0, x)$\n",
    "- Output range: [0, inf)\n",
    "- Fast computation, sparse activations, avoid vanishing gradients.\n",
    "- Problem: Dying ReLU - stucks at 0\n",
    "\n",
    "5. **leaky ReLU**\n",
    "- Fixes above problem by allowing small negative slope\n",
    "\n",
    "**How to choose (rule of thumb)**\n",
    "* Hidden layers: ReLU or Leaky ReLU\n",
    "* Binary classification output: Sigmoid\n",
    "* Multi-class classification output: Softmax\n",
    "* Regression output: No activation or linear\n",
    "\n",
    "6. **GeLU**: Used in LLMs - Gaussian Error Linear Unit\n",
    "- GeLU is a smooth activation functions that reduce that gates the output of neurons based on gaussian distribution.\n",
    "- Instead of hard thresholding like ReLU {neg: 0, posi: posi}, it scales activation proportionally to their magnitude, which lead smoother gradients.\n",
    "- LLMs are very deep neural networks trained with huge batch sizes, GeLU reduces gradient noise and improves convergence\n",
    "- Cons:\n",
    "- it is more computationally expensive than ReLU - tanh"
   ],
   "id": "2375f1cc4d079a26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:18.088569900Z",
     "start_time": "2026-02-05T01:02:17.996813300Z"
    }
   },
   "cell_type": "markdown",
   "source": "#### Questions for Activation Functions",
   "id": "b2db8e695c3092b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:18.229828200Z",
     "start_time": "2026-02-05T01:02:18.096508900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "##### 1ï¸âƒ£ Easy â€” Fundamentals (warm-up)\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> What is an activation function, and why canâ€™t we train a deep neural network without one?\n",
    "\n",
    "- Activation function allows neural networks to learn complex and non linear patterns. Along with, it also controls that output of neurons. If we don't use activation functions in deep neural networks, then the model with collapse into single linear functions.\n",
    "- Additionally, activation functions shape gradient flow during backpropagation, enabling effective learning in deep architectures.\n",
    "\n",
    "##### 2ï¸âƒ£ Medium â€” Practical choice\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Why are Sigmoid and Tanh rarely used in hidden layers of modern deep networks, while ReLU and its variants are preferred?\n",
    "* Sigmoid and Tanh have a problem called gradient vanishing for large inputs.\n",
    "* They are computationally expensive\n",
    "* Where as ReLU and leaky ReLU solve both of these problems. It deactivates for negative values and activates for positive ones.\n",
    "\n",
    "> Which makes it simple(no vanishing gradient) and reduces the computational power.\n",
    "Sigmoid and Tanh saturate for large positive or negative inputs, causing vanishing gradients that slow or stop learning in deep networks. ReLU and its variants avoid saturation in the positive region, allowing better gradient flow and faster convergence. ReLU also produces sparse activations and is computationally simpler, which makes it more scalable for deep architectures.\n",
    "\n",
    "##### 3ï¸âƒ£ Medium-Hard â€” Output layers & loss coupling\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Why is Softmax almost always paired with cross-entropy loss in multi-class classification?\n",
    "> What would break if we used MSE instead?\n",
    "\n",
    "* Softmax activation function calculates the probabilities of all output nodes of which all sums to one, output the prediction which has the most probability. which makes it ideal for multi class classification.\n",
    "* Softmax and cross entropy pairing results in well behaved gradients that strongly penalize confident wrong predictions.\n",
    "* Using MSE with softmax results in weaker gradients, slower convergence and poor classification, especially in multiclass settings.\n",
    "\n",
    "##### 4ï¸âƒ£ Hard â€” LLMs & fine-tuning context\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Modern LLMs (e.g., GPT-style models) do not use ReLU. Why are GELU or Swish preferred over ReLU in Transformers?\n",
    "\n",
    "\n",
    "\n",
    "##### 5ï¸âƒ£ Very Hard â€” Agentic AI & failure analysis\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Youâ€™re fine-tuning an LLM for an agentic system that performs tool calling and planning.\n",
    "> After fine-tuning, the agent becomes overly confident and collapses to repetitive actions.\n",
    "> How could activation functions or output activation behavior contribute to this, and how would you diagnose it?\n"
   ],
   "id": "d41fc786dd0da568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:33.088247700Z",
     "start_time": "2026-02-05T01:02:32.992500700Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Loss Functions\n",
    "\n",
    "loss functions measures how wrong is a model's output by calculating the difference between predicted label and actual labels.\n",
    "* BackPropagation uses the loss to compute gradients."
   ],
   "id": "3bba6ec82fe1931a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Core types of Loss Functions - Regression\n",
    "\n",
    "1. Regression Loss (MSE)\n",
    "* MSE measures the average squared difference between predicted $(\\hat{y_i})$ and actual $(y_i)$ values.\n",
    "* Fully differentiable even at zero, and is smooth convergence\n",
    "* Gradient grows linearly with errors, **which makes it sensitive to outliers.**\n",
    "* Larger Error -> Larger gradients. training becomes unstable.\n",
    "\n",
    "2. Mean Absolute Error (MAE)\n",
    "* Calculate average absolute distance between predicted and actual values.\n",
    "* Gradient is constant, non differentiable at zero.\n",
    "* Slower Convergence than MSE\n",
    "* Robust to outliers, not much effect.\n",
    "\n",
    "**Use MSE when:**\n",
    "\n",
    "* Errors should be penalized strongly\n",
    "* Data is relatively clean\n",
    "* You want stable & fast training\n",
    "* Typical DL regression (e.g., age estimation, depth prediction)\n",
    "\n",
    "**Use MAE when:**\n",
    "\n",
    "* Outliers exist\n",
    "* Error distribution is heavy-tailed\n",
    "* Median prediction matters more than mean"
   ],
   "id": "ea339dd16bb88553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Core types of Loss Functions - Classification\n",
    "\n",
    "**3. Cross Entropy {Binary CE and Categorical CE}**\n",
    "* Cross Entropy measure how well a predicted probability distribution matches the true distribution. There are two most common types of cross Entropy...\n",
    "\n",
    "a. Binary Cross Entropy\n",
    "* Most widely used log loss function in binary classification problems.\n",
    "* Sigmoid output - Sigmoid + BCE => Gives the logits or probabilities that are used to classify the labels.\n",
    "* Convergence faster than MSE for Classification. Avoid vanishing gradients.\n",
    "* Assumes balanced dataset.\n",
    "\n",
    "b. Categorical/Multi-Class Cross Entropy\n",
    "* Loss Function that is widely used for multiclass classification\n",
    "* Use one hot encoder to separate labels.\n",
    "* Softmax + CCE : Predicts probabilities for each output using softmax activation function.\n",
    "* do not use for multiple classes for one label use BCE instead.\n",
    "\n",
    "**4. Kullback-Leibler(KL) Divergence**<br>\n",
    "> â€œKL divergence measures how one probability distribution differs from another and is the core objective behind cross-entropy loss, variational inference, and alignment techniques used in LLM training such as RLHF.â€\n",
    "* Kullback Leibler Divergence is a measure from information theory that quantifies the difference between two probability distributions.\n",
    "* It tells us how much information is **lost when we approximate a true distribution P with another distribution Q.**\n",
    "* **Reinforcement Learning**: Stabilizes policy updates in algorithms like PPO by limiting divergence from previous policies.\n",
    "* **Language Models**: Guides token probability distributions during fine-tuning and model distillation.\n",
    "* **Generative Models**: Measures how closely generated data matches real data distributions.\n",
    "\n",
    "**5. Token Level Cross Entropy**\n",
    "* Token-level cross-entropy is the loss used to train language models, where the model is trained to predict the next token at each position in a sequence.\n",
    "* The loss is calculated per token and averaged over all tokens in the sequence of batch.\n",
    "\n",
    "**6. RLFH**\n",
    "* PPO: proximial policy optimization is the reinforcement learning algoirhthm most commonly used to update the model.\n",
    "* Improves a policy using reward feedback."
   ],
   "id": "52f6a5016fb565a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Questions for LossFunctions",
   "id": "cf6133e44354be9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:03:38.662441500Z",
     "start_time": "2026-02-05T01:03:38.572297600Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Perfect. Switching gears cleanly.\n",
    "**Senior-interviewer mode â†’ Loss functions**, tuned for **LLMs, fine-tuning, and agentic systems**.\n",
    "\n",
    "Iâ€™ll do this in **three tight steps**:\n",
    "\n",
    "1. Core understanding\n",
    "2. Practical usage\n",
    "3. Failure modes (where seniors stand out)\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1ï¸âƒ£ Easy â€” Fundamentals\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "> What is a loss function, and what role does it play during training?\n",
    "\n",
    "* Loss functions is a mathematical function that measure how far are the models predictions from actual or true target values. It is calculated after every forward pass and during backpropogation based on loss gradients updates the weights so that loss would be minimum.\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Whether you understand optimization, not just metrics\n",
    "\n",
    "**Strong answer should mention**\n",
    "\n",
    "* Quantifies model error\n",
    "* Guides gradient descent\n",
    "* Is differentiable\n",
    "* Defines *what â€œgoodâ€ means* for the model\n",
    "\n",
    "ðŸš© Red flag: describing loss as only â€œaccuracyâ€ or â€œevaluationâ€.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2ï¸âƒ£ Medium â€” Choosing the right loss\n",
    "\n",
    "**Question 2:**\n",
    "\n",
    "> Why do we use cross-entropy loss for classification instead of MSE?\n",
    "> In what situations *would* MSE be the right choice?\n",
    "\n",
    "* Cross entropy loss outputs probabilities (via either sigmoid or Softmax). It directly compares probability distribution. If the model is confident and wrong - larger the gradients and vice versa. This leads to faster and stable convergence. Where as MSE gradients becomes very small when predictions saturate near 0 and 1 that leads to slower learning.\n",
    "* Use MSE for regression problems, when there are less outliers in the dataset.\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Alignment between task, output space, and optimization\n",
    "* Understanding gradient behavior\n",
    "\n",
    "**Expected topics**\n",
    "\n",
    "* Probability distributions\n",
    "* Penalizing confident wrong predictions\n",
    "* Regression vs classification\n",
    "* Convergence speed\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3ï¸âƒ£ Medium-Hard â€” Regression nuance\n",
    "\n",
    "**Question 3:**\n",
    "\n",
    "> Compare MSE, MAE, and Huber loss.\n",
    "> When would you choose one over the others?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Robustness to outliers\n",
    "* Optimization smoothness\n",
    "* Practical tradeoffs\n",
    "\n",
    "ðŸ”¥ Bonus if they mention:\n",
    "\n",
    "* Sensitivity to noise\n",
    "* Gradient stability\n",
    "* Data distribution assumptions\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4ï¸âƒ£ Hard â€” LLM fine-tuning\n",
    "\n",
    "**Question 4:**\n",
    "\n",
    "> During LLM pretraining and fine-tuning, what loss function is actually being optimized?\n",
    "> How does this differ between pretraining, SFT, and RLHF?\n",
    "\n",
    "* Pretraining -> Token level cross entropy\n",
    "    * Durning pretraining, LLMs are trained as next token predictors.\n",
    "    * loss is calculated per token then averaged.\n",
    "* SFT(Supervised Fine-Tuning) -> Same cross entropy, but on instruction response data.\n",
    "    - Uses instruction/task - response/action pairs\n",
    "    - Uses same cross entropy as next token predictors\n",
    "    - Converts the noisy data to cleanly formatted data for users to easily understand.\n",
    "* RLHF -> Reinforcement learning objective(reward and punishment). Optimized via policy gradients.\n",
    "    - Now we optimze the LLM to maximize expected reward, not likelihood.\n",
    "    - Policy gradients are being used and KL penalty to keep the model close to the SFT policy.\n",
    "\n",
    "\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Real LLM knowledge (not surface-level)\n",
    "* Understanding of training pipelines\n",
    "\n",
    "**Expected mentions**\n",
    "\n",
    "* Next-token prediction\n",
    "* Cross-entropy over vocabulary\n",
    "* Policy optimization (PPO / KL penalty)\n",
    "* Reward modeling\n",
    "\n",
    "ðŸš© Red flag: saying â€œwe use accuracyâ€ or â€œjust cross-entropyâ€ without nuance.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 5ï¸âƒ£ Very Hard â€” Agentic AI failure analysis\n",
    "\n",
    "**Question 5:**\n",
    "\n",
    "> You fine-tune an LLM-based agent and notice it optimizes for short, repetitive actions rather than completing tasks correctly.\n",
    "> How could the loss function or reward design be causing this, and how would you fix it?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Reward hacking awareness\n",
    "* Systems thinking\n",
    "* Alignment intuition\n",
    "\n",
    "**Excellent answers mention**\n",
    "\n",
    "* Sparse vs dense rewards\n",
    "* Mode collapse\n",
    "* Over-optimization\n",
    "* KL regularization\n",
    "* Reward shaping\n",
    "* Credit assignment\n",
    "\n",
    "---\n",
    "\n",
    "#### Your turn\n",
    "\n",
    "Answer **Question 1â€“3 first** (donâ€™t jump to LLMs yet).\n",
    "Iâ€™ll:\n",
    "\n",
    "* Score you\n",
    "* Upgrade your answers to senior level\n",
    "* Then weâ€™ll move into **LLM + agentic loss functions**, where interviews get brutal.\n",
    "\n",
    "Start with **Question 1** when ready.\n"
   ],
   "id": "ed94eab85d6fff02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24120e47a14bffdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
