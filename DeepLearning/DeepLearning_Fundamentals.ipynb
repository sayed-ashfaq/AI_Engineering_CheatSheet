{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Deep Learning Fundamentals Revision",
   "id": "3cb379b273663733"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Topics covering\n",
    "* [X] ~~Neural network Fundamentals - Linearity/Non linearity~~\n",
    "* [x] ~~Activation Functions~~\n",
    "* [ ] Loss Functions - Cross Entropy, MSE vs MAE, Perplexity\n",
    "* [ ] Optimizers\n",
    "* [ ] Learning Rate Strategies\n",
    "* [ ] Regularization\n",
    "* [ ] Normalization\n",
    "* [ ] Transformers arch and Attention\n",
    "* [ ] Evaluation\n",
    "\n",
    "Every topic you review must answer 3 questions:\n",
    "\n",
    "* What problem does this solve?\n",
    "* When does it fail?\n",
    "* What knob do I turn?\n",
    "\n",
    "If you canâ€™t answer those â†’ you donâ€™t â€œknowâ€ it yet."
   ],
   "id": "abf29e40b839eb57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### How to Study like an Engineer not a student",
   "id": "ec0395038809e482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Good â€” this is the *right* question.\n",
    "Hereâ€™s the **concrete, no-nonsense answer** to *â€œwhat am I supposed to do?â€* given that expectation.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸŽ¯ What You Are ACTUALLY Supposed to Do (One-Day Mode)\n",
    "\n",
    "Your job is **not** to study more theory.\n",
    "Your job is to practice **thinking like the engineer who owns the model**.\n",
    "\n",
    "Below is a **step-by-step action plan** you can literally follow today.\n",
    "\n",
    "---\n",
    "\n",
    "##### 1ï¸âƒ£ Switch Your Study Mode (Non-Negotiable)\n",
    "\n",
    "Stop asking:\n",
    "\n",
    "> â€œDo I remember this?â€\n",
    "\n",
    "Start asking:\n",
    "\n",
    "> â€œIf this breaks in production, what would I change first?â€\n",
    "\n",
    "Every topic you review must answer **3 questions**:\n",
    "\n",
    "* What problem does this solve?\n",
    "* When does it fail?\n",
    "* What knob do I turn?\n",
    "\n",
    "If you canâ€™t answer those â†’ you donâ€™t â€œknowâ€ it yet.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2ï¸âƒ£ Do This Loop for Every Topic (THE Core Skill)\n",
    "\n",
    "###### The **Engineer Loop** (repeat 8â€“10 times today)\n",
    "\n",
    "For **each** concept (e.g. AdamW, LoRA, attention):\n",
    "\n",
    "1. **Explain it out loud in plain English** (no math)\n",
    "2. **Name 1 reason it fails**\n",
    "3. **Name 1 trade-off**\n",
    "\n",
    "Example (AdamW):\n",
    "\n",
    "* What it is: Adaptive optimizer with decoupled weight decay\n",
    "* Fails when: LR too high â†’ unstable fine-tuning\n",
    "* Trade-off: Faster convergence vs less predictable generalization\n",
    "\n",
    "If you can do this â†’ interview-ready.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3ï¸âƒ£ Mandatory â€œDebug Thinkingâ€ Practice\n",
    "\n",
    "Interviewers LOVE this.\n",
    "\n",
    "Pick **one LLM fine-tuning scenario** and rehearse it:\n",
    "\n",
    "###### Scenario:\n",
    "\n",
    "> â€œYour fine-tuned LLM outputs repetitive, low-quality answers.â€\n",
    "\n",
    "Your mental checklist must be automatic:\n",
    "\n",
    "* Data quality (format, duplicates, instruction clarity)\n",
    "* Learning rate too high\n",
    "* Overfitting (too many epochs)\n",
    "* Decoding issue (temperature, top-p)\n",
    "* Tokenization mismatch\n",
    "\n",
    "Say this **in order**.\n",
    "This signals *ownership*.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4ï¸âƒ£ Force Yourself to Talk (Critical)\n",
    "\n",
    "Silent studying will **fail you**.\n",
    "\n",
    "###### Do this:\n",
    "\n",
    "* Open a doc or voice note\n",
    "* Explain these **out loud**:\n",
    "\n",
    "  * Attention\n",
    "  * LoRA\n",
    "  * Why fine-tuning fails\n",
    "  * AdamW vs SGD\n",
    "\n",
    "If you hesitate â†’ thatâ€™s your weak spot. Fix only those.\n",
    "\n",
    "---\n",
    "\n",
    "##### 5ï¸âƒ£ Learn to Say â€œIt Dependsâ€ Correctly\n",
    "\n",
    "This is a senior-level signal.\n",
    "\n",
    "Bad answer:\n",
    "\n",
    "> â€œAdam is better.â€\n",
    "\n",
    "Good answer:\n",
    "\n",
    "> â€œIt depends on model size, batch size, and stability needs.â€\n",
    "\n",
    "Then name **one concrete factor**.\n",
    "\n",
    "Interviewers want **judgment**, not certainty.\n",
    "\n",
    "---\n",
    "\n",
    "##### 6ï¸âƒ£ What NOT to Do (Very Important)\n",
    "\n",
    "âŒ Donâ€™t re-derive backprop\n",
    "âŒ Donâ€™t memorize equations\n",
    "âŒ Donâ€™t chase exotic architectures\n",
    "âŒ Donâ€™t over-optimize metrics talk\n",
    "\n",
    "None of this gets you hired.\n",
    "\n",
    "---\n",
    "\n",
    "##### 7ï¸âƒ£ Final 60-Minute Drill (Before Interview)\n",
    "\n",
    "Do this exact order:\n",
    "\n",
    "1. Explain **attention** in 2 minutes\n",
    "2. Explain **LoRA** in 1 minute\n",
    "3. Explain **why fine-tuning fails** in 2 minutes\n",
    "4. Explain **trade-offs of decoding strategies**\n",
    "5. Answer:\n",
    "\n",
    "   > â€œHow would you improve performance without changing the model?â€\n",
    "\n",
    "If you can do this calmly â†’ you are *absolutely* hireable.\n",
    "\n",
    "---\n",
    "\n",
    "##### The Truth (Coach Mode)\n",
    "\n",
    "Companies hire people who:\n",
    "\n",
    "* Donâ€™t panic when models misbehave\n",
    "* Know which knob to turn first\n",
    "* Can explain decisions clearly\n",
    "\n",
    "Youâ€™re not trying to be brilliant.\n",
    "Youâ€™re trying to be **reliable under pressure**.\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "* Simulate a **real interview** (Iâ€™ll push you)\n",
    "* Turn this into a **1-page interview cheat sheet**\n",
    "* Drill you with **failure-mode questions only**\n",
    "\n",
    "Tell me which one.\n"
   ],
   "id": "68bf47dd427d53e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NN Basics",
   "id": "c5ae836aef555278"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* `Layer`: Layer is a group of neurons that process the input at the same stage\n",
    "* `Weights`: Learned parameters that determine how important each input is.\n",
    "* `bias`: It is constant that is added to weighted sum\n",
    "* `Activation Function`: **Allows the neural networks to understand non linearity** in the data allowing to learn and represent complex data patterns. If no activation function it would collapse into **single linear model**."
   ],
   "id": "1b4e3e62e3ef9812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Activation Functions\n",
    "Activation Functions are mathematical functions applied to neuron's output in a neural network. They decide how much of signal passes forward.\n",
    "\n",
    "> Apart from introducing non-linearity it also controls the output of neurons in neural network"
   ],
   "id": "c024528e36be791c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Common Activation Functions are\n",
    "1. **Sigmoid**\n",
    "- $ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "- Output range - (0 , 1)\n",
    "- Binary Classification output layers.\n",
    "- Problems are Vanishing gradients, Outputs are not zero centered\n",
    "\n",
    "2. **Tanh**\n",
    "- Output range: (-1, 1)\n",
    "- Zero Centered better than sigmoid. Strong gradients\n",
    "- Problem: vanishing gradient\n",
    "\n",
    "3. **Softmax**\n",
    "- Converts a vector of scores into probabilities that sums upto 1.\n",
    "- Used for multiclass classification output layers.\n",
    "\n",
    "4. **ReLU**\n",
    "- $ f(x) = max(0, x)$\n",
    "- Output range: [0, inf)\n",
    "- Fast computation, sparse activations, avoid vanishing gradients.\n",
    "- Problem: Dying ReLU - stucks at 0\n",
    "\n",
    "5. **leaky ReLU**\n",
    "- Fixes above problem by allowing small negative slope\n",
    "\n",
    "**How to choose (rule of thumb)**\n",
    "* Hidden layers: ReLU or Leaky ReLU\n",
    "* Binary classification output: Sigmoid\n",
    "* Multi-class classification output: Softmax\n",
    "* Regression output: No activation or linear\n",
    "\n",
    "6. **GeLU**: Used in LLMs - Gaussian Error Linear Unit\n",
    "- GeLU is a smooth activation functions that reduce that gates the output of neurons based on gaussian distribution.\n",
    "- Instead of hard thresholding like ReLU {neg: 0, posi: posi}, it scales activation proportionally to their magnitude, which lead smoother gradients.\n",
    "- LLMs are very deep neural networks trained with huge batch sizes, GeLU reduces gradient noise and improves convergence\n",
    "- Cons:\n",
    "- it is more computationally expensive than ReLU - tanh"
   ],
   "id": "2375f1cc4d079a26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:18.088569900Z",
     "start_time": "2026-02-05T01:02:17.996813300Z"
    }
   },
   "cell_type": "markdown",
   "source": "#### Questions for Activation Functions",
   "id": "b2db8e695c3092b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:18.229828200Z",
     "start_time": "2026-02-05T01:02:18.096508900Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "##### 1ï¸âƒ£ Easy â€” Fundamentals (warm-up)\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> What is an activation function, and why canâ€™t we train a deep neural network without one?\n",
    "\n",
    "- Activation function allows neural networks to learn complex and non linear patterns. Along with, it also controls that output of neurons. If we don't use activation functions in deep neural networks, then the model with collapse into single linear functions.\n",
    "- Additionally, activation functions shape gradient flow during backpropagation, enabling effective learning in deep architectures.\n",
    "\n",
    "##### 2ï¸âƒ£ Medium â€” Practical choice\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Why are Sigmoid and Tanh rarely used in hidden layers of modern deep networks, while ReLU and its variants are preferred?\n",
    "* Sigmoid and Tanh have a problem called gradient vanishing for large inputs.\n",
    "* They are computationally expensive\n",
    "* Where as ReLU and leaky ReLU solve both of these problems. It deactivates for negative values and activates for positive ones.\n",
    "\n",
    "> Which makes it simple(no vanishing gradient) and reduces the computational power.\n",
    "Sigmoid and Tanh saturate for large positive or negative inputs, causing vanishing gradients that slow or stop learning in deep networks. ReLU and its variants avoid saturation in the positive region, allowing better gradient flow and faster convergence. ReLU also produces sparse activations and is computationally simpler, which makes it more scalable for deep architectures.\n",
    "\n",
    "##### 3ï¸âƒ£ Medium-Hard â€” Output layers & loss coupling\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Why is Softmax almost always paired with cross-entropy loss in multi-class classification?\n",
    "> What would break if we used MSE instead?\n",
    "\n",
    "* Softmax activation function calculates the probabilities of all output nodes of which all sums to one, output the prediction which has the most probability. which makes it ideal for multi class classification.\n",
    "* Softmax and cross entropy pairing results in well behaved gradients that strongly penalize confident wrong predictions.\n",
    "* Using MSE with softmax results in weaker gradients, slower convergence and poor classification, especially in multiclass settings.\n",
    "\n",
    "##### 4ï¸âƒ£ Hard â€” LLMs & fine-tuning context\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Modern LLMs (e.g., GPT-style models) do not use ReLU. Why are GELU or Swish preferred over ReLU in Transformers?\n",
    "\n",
    "\n",
    "\n",
    "##### 5ï¸âƒ£ Very Hard â€” Agentic AI & failure analysis\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Youâ€™re fine-tuning an LLM for an agentic system that performs tool calling and planning.\n",
    "> After fine-tuning, the agent becomes overly confident and collapses to repetitive actions.\n",
    "> How could activation functions or output activation behavior contribute to this, and how would you diagnose it?\n"
   ],
   "id": "d41fc786dd0da568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:02:33.088247700Z",
     "start_time": "2026-02-05T01:02:32.992500700Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Loss Functions\n",
    "\n",
    "loss functions measures how wrong is a model's output by calculating the difference between predicted label and actual labels.\n",
    "* BackPropagation uses the loss to compute gradients."
   ],
   "id": "3bba6ec82fe1931a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Core types of Loss Functions\n",
    "1. Regression Loss (MSE)\n",
    "2. Mean Absolute Error (MAE)\n",
    "3. Cross Entropy {Binary CE and Categorical CE}\n",
    "4. KL Divergence\n",
    "5. Token Level Cross Entropy"
   ],
   "id": "ea339dd16bb88553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Questions for LossFunctions",
   "id": "cf6133e44354be9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T01:03:38.662441500Z",
     "start_time": "2026-02-05T01:03:38.572297600Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Perfect. Switching gears cleanly.\n",
    "**Senior-interviewer mode â†’ Loss functions**, tuned for **LLMs, fine-tuning, and agentic systems**.\n",
    "\n",
    "Iâ€™ll do this in **three tight steps**:\n",
    "\n",
    "1. Core understanding\n",
    "2. Practical usage\n",
    "3. Failure modes (where seniors stand out)\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1ï¸âƒ£ Easy â€” Fundamentals\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "> What is a loss function, and what role does it play during training?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Whether you understand optimization, not just metrics\n",
    "\n",
    "**Strong answer should mention**\n",
    "\n",
    "* Quantifies model error\n",
    "* Guides gradient descent\n",
    "* Is differentiable\n",
    "* Defines *what â€œgoodâ€ means* for the model\n",
    "\n",
    "ðŸš© Red flag: describing loss as only â€œaccuracyâ€ or â€œevaluationâ€.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2ï¸âƒ£ Medium â€” Choosing the right loss\n",
    "\n",
    "**Question 2:**\n",
    "\n",
    "> Why do we use cross-entropy loss for classification instead of MSE?\n",
    "> In what situations *would* MSE be the right choice?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Alignment between task, output space, and optimization\n",
    "* Understanding gradient behavior\n",
    "\n",
    "**Expected topics**\n",
    "\n",
    "* Probability distributions\n",
    "* Penalizing confident wrong predictions\n",
    "* Regression vs classification\n",
    "* Convergence speed\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3ï¸âƒ£ Medium-Hard â€” Regression nuance\n",
    "\n",
    "**Question 3:**\n",
    "\n",
    "> Compare MSE, MAE, and Huber loss.\n",
    "> When would you choose one over the others?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Robustness to outliers\n",
    "* Optimization smoothness\n",
    "* Practical tradeoffs\n",
    "\n",
    "ðŸ”¥ Bonus if they mention:\n",
    "\n",
    "* Sensitivity to noise\n",
    "* Gradient stability\n",
    "* Data distribution assumptions\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4ï¸âƒ£ Hard â€” LLM fine-tuning\n",
    "\n",
    "**Question 4:**\n",
    "\n",
    "> During LLM pretraining and fine-tuning, what loss function is actually being optimized?\n",
    "> How does this differ between pretraining, SFT, and RLHF?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Real LLM knowledge (not surface-level)\n",
    "* Understanding of training pipelines\n",
    "\n",
    "**Expected mentions**\n",
    "\n",
    "* Next-token prediction\n",
    "* Cross-entropy over vocabulary\n",
    "* Policy optimization (PPO / KL penalty)\n",
    "* Reward modeling\n",
    "\n",
    "ðŸš© Red flag: saying â€œwe use accuracyâ€ or â€œjust cross-entropyâ€ without nuance.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 5ï¸âƒ£ Very Hard â€” Agentic AI failure analysis\n",
    "\n",
    "**Question 5:**\n",
    "\n",
    "> You fine-tune an LLM-based agent and notice it optimizes for short, repetitive actions rather than completing tasks correctly.\n",
    "> How could the loss function or reward design be causing this, and how would you fix it?\n",
    "\n",
    "**What Iâ€™m testing**\n",
    "\n",
    "* Reward hacking awareness\n",
    "* Systems thinking\n",
    "* Alignment intuition\n",
    "\n",
    "**Excellent answers mention**\n",
    "\n",
    "* Sparse vs dense rewards\n",
    "* Mode collapse\n",
    "* Over-optimization\n",
    "* KL regularization\n",
    "* Reward shaping\n",
    "* Credit assignment\n",
    "\n",
    "---\n",
    "\n",
    "#### Your turn\n",
    "\n",
    "Answer **Question 1â€“3 first** (donâ€™t jump to LLMs yet).\n",
    "Iâ€™ll:\n",
    "\n",
    "* Score you\n",
    "* Upgrade your answers to senior level\n",
    "* Then weâ€™ll move into **LLM + agentic loss functions**, where interviews get brutal.\n",
    "\n",
    "Start with **Question 1** when ready.\n"
   ],
   "id": "ed94eab85d6fff02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24120e47a14bffdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
