{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# System Design Questions",
   "id": "4968af4b23d13e94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Easy: You need to deploy an LLM-powered chatbot for a government website. What are the key components you would include to make it scalable and reliable?\n",
    "\n",
    "2. Medium: Design an end-to-end multilingual voice assistant pipeline (ASR → LLM → TTS). Where do you handle language detection, latency constraints, and fallback when speech recognition fails?\n",
    "\n",
    "3. Medium–Hard: A ministry wants an AI system to summarize large legal documents and answer questions. Would you use RAG, fine-tuning, or both? Explain your architecture and trade-offs.\n",
    "\n",
    "4. Hard: Design an agentic AI system that can handle citizen service requests by calling internal tools (databases, ticketing APIs). How do you prevent hallucinated tool calls and ensure auditability?\n",
    "\n",
    "5. Very Hard: After deployment, your AI assistant performs well normally but fails catastrophically on rare edge cases (accent bias, incorrect legal advice, high latency spikes). How do you detect, monitor, and systematically reduce these failures over time?\n"
   ],
   "id": "b6f0bd34eda37d77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Good. These are the **5 most efficient system design questions** (easy → hard) that cover **RAG, fine-tuning, agents, orchestration, and production AI** without wasting time.\n",
    "\n",
    "Answer them in this format only:\n",
    "\n",
    "**Problem → Approach → Tradeoffs → Metrics → Risks → Next steps**\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Easy — RAG Baseline Design\n",
    "\n",
    "**Question:**\n",
    "Design a **Document Q&A system** for internal government officers to query policy PDFs.\n",
    "\n",
    "Constraints:\n",
    "\n",
    "* 500k documents\n",
    "* Must return answers in < 2 seconds\n",
    "* Sources must be cited\n",
    "\n",
    "What is your architecture end-to-end?\n",
    "\n",
    "**Follow-ups:**\n",
    "\n",
    "* Where do embeddings live?\n",
    "* How do you handle document updates\n",
    "\n",
    "\n",
    "### ✅ Correct Senior Answer (what you should say)\n",
    "\n",
    "#### Problem\n",
    "\n",
    "We need a **Document Q&A system** for 500K government policy PDFs with:\n",
    "\n",
    "* <2s latency\n",
    "* Answer must include citations\n",
    "* High reliability for internal officers\n",
    "\n",
    "---\n",
    "\n",
    "#### Approach (Architecture)\n",
    "\n",
    "##### 1. Offline Ingestion Pipeline\n",
    "\n",
    "* Parse PDFs → extract clean text\n",
    "* Chunk documents (300–500 tokens)\n",
    "* Generate embeddings using a multilingual embedding model\n",
    "* Store chunks in a **vector database** with metadata:\n",
    "\n",
    "```json\n",
    "{\n",
    "  chunk_text,\n",
    "  doc_id,\n",
    "  page_number,\n",
    "  section_title,\n",
    "  timestamp\n",
    "}\n",
    "```\n",
    "\n",
    "This metadata enables citation.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Retrieval Layer (Fast + Accurate)\n",
    "\n",
    "At query time:\n",
    "\n",
    "* User query → embedding\n",
    "* Retrieve top-k chunks using:\n",
    "  * Dense similarity search\n",
    "  * Optional hybrid BM25 + vector search for legal text\n",
    "\n",
    "This ensures both semantic + keyword accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Generation Layer (Cited Answer)\n",
    "\n",
    "* Pass retrieved chunks + query into the LLM\n",
    "* Prompt enforces:\n",
    "* Only answer from context\n",
    "* Cite page/section for every claim\n",
    "* If not found → say “Not in documents”\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Latency Optimizations (<2s SLA)\n",
    "\n",
    "* Use ANN indexes (HNSW/IVF) in vector DB\n",
    "* Cache embeddings + frequent queries\n",
    "* Stream responses\n",
    "* Use smaller tuned models for generation if needed\n",
    "\n",
    "---\n",
    "\n",
    "#### Tradeoffs\n",
    "\n",
    "* RAG avoids retraining when policies update\n",
    "* Fine-tuning improves style but risks stale knowledge\n",
    "* Hybrid search improves recall but increases complexity\n",
    "\n",
    "---\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "* Retrieval Recall@k\n",
    "* Answer groundedness (% supported by sources)\n",
    "* Latency p95 <2s\n",
    "* Citation accuracy\n",
    "* User satisfaction\n",
    "\n",
    "---\n",
    "\n",
    "#### Risks + Mitigation\n",
    "\n",
    "* Hallucination → strict context-only prompting + refusal\n",
    "* Stale docs → incremental re-indexing pipeline\n",
    "* Security → access control per officer role\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "* Add evaluation harness for retrieval + citations\n",
    "* Monitor production drift\n",
    "* Expand to multilingual queries\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# 2) Medium — RAG Failure & Evaluation\n",
    "\n",
    "**Question:**\n",
    "Your RAG assistant works well on common queries but fails badly on rare edge cases.\n",
    "\n",
    "How do you:\n",
    "\n",
    "* detect these failures early\n",
    "* evaluate retrieval quality\n",
    "* reduce hallucinations over time?\n",
    "\n",
    "**Follow-ups:**\n",
    "\n",
    "* What offline + online metrics do you track?\n",
    "\n",
    "---\n",
    "\n",
    "# 3) Medium–Hard — Fine-tuning vs RAG Decision\n",
    "\n",
    "**Question:**\n",
    "A ministry wants a chatbot that answers citizen questions about complex legal rules.\n",
    "\n",
    "You have:\n",
    "\n",
    "* 30k labeled Q&A pairs\n",
    "* Privacy constraints (data cannot leave premises)\n",
    "* Need multilingual support\n",
    "\n",
    "Do you choose:\n",
    "\n",
    "* Fine-tuning (LoRA)\n",
    "* RAG\n",
    "* Hybrid\n",
    "\n",
    "Explain why.\n",
    "\n",
    "**Follow-ups:**\n",
    "\n",
    "* What changes when laws update every month?\n",
    "\n",
    "---\n",
    "\n",
    "# 4) Hard — Agentic Workflow + Tool Orchestration\n",
    "\n",
    "**Question:**\n",
    "Design an AI agent that can:\n",
    "\n",
    "* understand user intent\n",
    "* fetch citizen complaint status from databases\n",
    "* escalate tickets via APIs\n",
    "* generate summaries for human officers\n",
    "\n",
    "It must be:\n",
    "\n",
    "* auditable\n",
    "* safe\n",
    "* resistant to hallucinated tool calls\n",
    "\n",
    "Where do you put:\n",
    "\n",
    "* planner\n",
    "* tool executor\n",
    "* memory\n",
    "* verification layer?\n",
    "\n",
    "---\n",
    "\n",
    "# 5) Very Hard — Government-Grade Voice Agent at Scale\n",
    "\n",
    "**Question:**\n",
    "Design a **multilingual voice agent** for a national helpline:\n",
    "\n",
    "* Hindi, English, Tamil\n",
    "* Handles 10k concurrent calls\n",
    "* Must degrade safely under load\n",
    "* Must be monitored + explainable\n",
    "\n",
    "Describe:\n",
    "\n",
    "* ASR → LLM → TTS pipeline\n",
    "* Latency budget\n",
    "* Fallback mechanisms\n",
    "* Monitoring and bias mitigation\n",
    "\n",
    "---\n",
    "\n",
    "## Brutal Interview Rule\n",
    "\n",
    "If you can answer #4 and #5 crisply, you’re senior.\n",
    "If not, you’re still mid-level.\n",
    "\n",
    "---\n",
    "\n",
    "Pick **Question 1** and answer in the required structure.\n",
    "I will interrupt and correct you like a real interviewer.\n"
   ],
   "id": "d45f2875f88f76cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
